{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid turning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "from IPython.display import Video\n",
    "from enum import Enum, auto\n",
    "\n",
    "from flygym.mujoco import Parameters\n",
    "from flygym.mujoco.arena import FlatTerrain\n",
    "from flygym.mujoco.examples.obstacle_arena import ObstacleOdorArena\n",
    "from flygym.mujoco.examples.turning_controller import HybridTurningNMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Finite Sate Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class movingFSM:\n",
    "    def __init__(self):\n",
    "        # Start in the 'go straight' state\n",
    "        self.state = 'go straight'\n",
    "        self.turn_threshold = 0\n",
    "        # Setting up the methods as dictionary entries simulating a switch\n",
    "        self.states = {\n",
    "            'go straight': self.go_straight,\n",
    "            'turn right': self.turn_right,\n",
    "            'turn left': self.turn_left,\n",
    "            'reach and turn': self.reach_and_turn\n",
    "        }\n",
    "        \n",
    "    def go_straight(self, right_sense, left_sense):\n",
    "        if right_sense > self.turn_threshold:\n",
    "            self.state = 'turn left'\n",
    "        elif left_sense > self.turn_threshold:\n",
    "            self.state = 'turn right'\n",
    "        # Continue going straight if no matching sensation\n",
    "        else:\n",
    "            turning_bias = 0\n",
    "            self.state = 'go straight'\n",
    "    \n",
    "    def turn_right(self, right_sense, left_sense):\n",
    "        if right_sense > self.turn_threshold:\n",
    "            self.state = 'reach and turn'\n",
    "        elif left_sense > self.turn_threshold:\n",
    "            self.state = 'turn right'\n",
    "        # Continue going straight if no matching sensation\n",
    "        else:\n",
    "            turning_bias = 0\n",
    "            self.state = 'go straight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m run_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      3\u001b[0m num_decision_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(run_time \u001b[38;5;241m/\u001b[39m decision_interval)\n\u001b[1;32m----> 4\u001b[0m physics_steps_per_decision_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(decision_interval \u001b[38;5;241m/\u001b[39m \u001b[43msim_params\u001b[49m\u001b[38;5;241m.\u001b[39mtimestep)\n\u001b[0;32m      6\u001b[0m obs_hist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m odor_history \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sim_params' is not defined"
     ]
    }
   ],
   "source": [
    "decision_interval = 0.05\n",
    "run_time = 5\n",
    "num_decision_steps = int(run_time / decision_interval)\n",
    "physics_steps_per_decision_step = int(decision_interval / sim_params.timestep)\n",
    "\n",
    "obs_hist = []\n",
    "odor_history = []\n",
    "obs, _ = sim.reset(seed)\n",
    "for i in trange(num_decision_steps):\n",
    "    I_reshaped = obs[\"odor_intensity\"].reshape((odor_dimensions, 2, 2))\n",
    "    I = np.average(I_reshaped, axis=1, weights=[120, 1200])\n",
    "\n",
    "    # Calculate the left-right asymmetry in the odor intensities\n",
    "    I_l, I_r = I[:, 0], I[:, 1]\n",
    "    denom = (I_l + I_r) / 2\n",
    "    denom[denom == 0] = 1  # Avoid division by zero\n",
    "    delta_I = (I_l - I_r) / denom\n",
    "\n",
    "    # Calculate the weighted sum of the asymmetries for each odor\n",
    "    s = np.dot(gains, delta_I)\n",
    "\n",
    "    # Calculate the turning bias\n",
    "    b = np.tanh(s**2)\n",
    "\n",
    "    control_signal = np.ones((2,))\n",
    "    side_to_modulate = int(s > 0)\n",
    "    modulation_amount = b * 0.8\n",
    "    control_signal[side_to_modulate] -= modulation_amount\n",
    "\n",
    "    for j in range(physics_steps_per_decision_step):\n",
    "        obs, _, _, _, _ = sim.step(control_signal)\n",
    "        rendered_img = sim.render()\n",
    "        if rendered_img is not None:\n",
    "            # record odor intensity too for video\n",
    "            odor_history.append(obs[\"odor_intensity\"])\n",
    "        obs_hist.append(obs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flygym.mujoco\n",
    "from tqdm import trange\n",
    "\n",
    "# We start by creating a simple arena\n",
    "flat_terrain_arena = FlatTerrain()\n",
    "\n",
    "# Then, we add visual and olfactory features on top of it\n",
    "arena = ObstacleOdorArena(\n",
    "    terrain=flat_terrain_arena,\n",
    "    obstacle_positions=np.array([(7.5, 0), (12.5, 5), (17.5, -5)]),\n",
    "    marker_size=0.5,\n",
    "    obstacle_colors=[(0.14, 0.14, 0.2, 1), (0.2, 0.8, 0.2, 1), (0.2, 0.2, 0.8, 1)],\n",
    "    user_camera_settings=((13, -18, 9), (np.deg2rad(65), 0, 0), 45),\n",
    ")\n",
    "\n",
    "contact_sensor_placements = [\n",
    "    f\"{leg}{segment}\"\n",
    "    for leg in [\"LF\", \"LM\", \"LH\", \"RF\", \"RM\", \"RH\"]\n",
    "    for segment in [\"Tibia\", \"Tarsus1\", \"Tarsus2\", \"Tarsus3\", \"Tarsus4\", \"Tarsus5\"]\n",
    "]\n",
    "\n",
    "run_time = 1\n",
    "sim_params = flygym.mujoco.Parameters(\n",
    "    timestep=1e-4, \n",
    "    render_mode=\"saved\", \n",
    "    render_playspeed=0.1, \n",
    "    draw_contacts=False,\n",
    "    render_camera=\"user_cam\"\n",
    ")\n",
    "\n",
    "nmf = HybridTurningNMF(\n",
    "    sim_params=sim_params,\n",
    "    init_pose=\"stretch\",\n",
    "    spawn_pos=(13, -5, 0.2),\n",
    "    spawn_orientation=(0, 0, np.pi / 2 + np.deg2rad(70)),\n",
    "    contact_sensor_placements=contact_sensor_placements,\n",
    "    arena=arena\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact_forces in x,y,z direction of all the segments(legs) in contact sensory placements (nmf.contact_sensor_placements)\n",
    "\n",
    "#This gives back the contact forces of the five segments of the left and right leg \n",
    "#without the segment touching the ground\n",
    "\n",
    "sensory_feedback_left = np.array([obs[\"contact_forces\"][:5, :] for obs in obs_hist])\n",
    "sensory_feedback_right = np.array([obs[\"contact_forces\"][18:23, :] for obs in obs_hist])\n",
    "\n",
    "\n",
    "#summed up contact forces of five of the six segments of the legs (left and right)\n",
    "#axis = 1 to sum up each row of the contact forces of the five segments of the legs\n",
    "#axis = 0 would sum up each column of the contact forces of the five segments of the legs\n",
    "\n",
    "sensory_feedback_sum_left = sensory_feedback_left.sum(axis=1)\n",
    "sensory_feedback_sum_right = sensory_feedback_right.sum(axis=1)\n",
    "\n",
    "sensory_feedback = np.array([obs[\"contact_forces\"] for obs in obs_hist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:11<00:00, 140.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/pillars.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, info = nmf.reset()\n",
    "for i in trange(int(run_time / nmf.sim_params.timestep)):\n",
    "    curr_time = i * nmf.sim_params.timestep\n",
    "    if curr_time < 1:\n",
    "        action = np.array([1.2, 0.2])\n",
    "    else:\n",
    "        action = np.array([0.2, 1.2])\n",
    "\n",
    "    obs, reward, terminated, truncated, info = nmf.step(action)\n",
    "    nmf.render()\n",
    "\n",
    "nmf.save_video(\"./outputs/pillars.mp4\")\n",
    "Video(\"./outputs/pillars.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running simulation with turning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:13<00:00, 150.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/pillars.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enum import Enum, auto\n",
    "\n",
    "# random state seed for reproducibility\n",
    "seed = 1\n",
    "\n",
    "class State(Enum):\n",
    "    GO_STRAIGHT = 1\n",
    "    TURN_LEFT = 2\n",
    "    TURN_RIGHT = 3\n",
    "    REVERSE_LEFT = 4\n",
    "    REVERSE_RIGHT = 5\n",
    "    REACH_AND_TURN = 6\n",
    "\n",
    "# Example of setting a current state\n",
    "current_state = State.GO_STRAIGHT\n",
    "\n",
    "decision_interval = 0.2\n",
    "run_time = 2\n",
    "num_decision_steps = int(run_time / decision_interval)\n",
    "physics_steps_per_decision_step = int(decision_interval / sim_params.timestep)\n",
    "\n",
    "low_force_thresh = 1\n",
    "high_force_thresh = 3\n",
    "enforce_time = 0\n",
    "delay = 0.2\n",
    "\n",
    "obs_hist = []\n",
    "odor_history = []\n",
    "obs, _ = nmf.reset(seed)\n",
    "bias = np.array([0,0])\n",
    "for i in trange(int(run_time / nmf.sim_params.timestep)):\n",
    "    curr_time = i * nmf.sim_params.timestep\n",
    "    left_sense = np.array(obs[\"contact_forces\"][:5, 0:2])\n",
    "    right_sense = np.array(obs[\"contact_forces\"][18:23, 0:2])\n",
    "    left_sense_sum = left_sense.sum()\n",
    "    right_sense_sum = right_sense.sum()\n",
    "\n",
    "    if right_sense_sum > low_force_thresh:\n",
    "        if current_state == State.GO_STRAIGHT:\n",
    "            if right_sense_sum > high_force_thresh:\n",
    "                current_state = State.REVERSE_LEFT\n",
    "                # reverse while turning left function\n",
    "            else:\n",
    "                current_state = State.TURN_LEFT\n",
    "                bias = np.array([-2, 0])\n",
    "        elif current_state == State.TURN_LEFT:\n",
    "            current_state = State.REVERSE_LEFT\n",
    "            # reverse while turning left function\n",
    "        elif current_state == State.REVERSE_LEFT:\n",
    "            # reverse while turning left function\n",
    "            trash = 0\n",
    "        elif current_state == State.TURN_RIGHT or current_state == State.REVERSE_RIGHT:\n",
    "            current_state == State.REACH_AND_TURN\n",
    "            # call reach and turn function\n",
    "        enforce_time =  curr_time + delay\n",
    "    elif left_sense_sum > low_force_thresh:\n",
    "        if current_state == State.GO_STRAIGHT:\n",
    "            if left_sense_sum > high_force_thresh:\n",
    "                current_state = State.REVERSE_RIGHT\n",
    "                # reverse while turning right function\n",
    "            else:\n",
    "                current_state = State.TURN_RIGHT\n",
    "                bias = np.array([0, -2])\n",
    "        elif current_state == State.TURN_LEFT or current_state == State.REVERSE_LEFT:\n",
    "            current_state == State.REACH_AND_TURN\n",
    "            # call reach and turn function\n",
    "        elif current_state == State.TURN_RIGHT:\n",
    "            current_state = State.REVERSE_RIGHT\n",
    "            # reverse while turning right function\n",
    "        elif current_state == State.REACH_AND_TURN:\n",
    "            # reverse while turning left function\n",
    "            trash = 0\n",
    "        enforce_time =  curr_time + delay\n",
    "    elif curr_time >= enforce_time:\n",
    "        current_state = State.GO_STRAIGHT\n",
    "        bias = np.array([0,0])\n",
    "    \n",
    "    control_signal = np.array([1, 1]) + bias\n",
    "\n",
    "    obs, reward, terminated, truncated, info = nmf.step(control_signal)\n",
    "    nmf.render()\n",
    "\n",
    "nmf.save_video(\"./outputs/pillars.mp4\")\n",
    "Video(\"./outputs/pillars.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
